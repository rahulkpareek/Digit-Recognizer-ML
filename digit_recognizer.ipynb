{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the test data\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv('test.csv')\n",
    "print(\"shape of training data :\", train_df.shape)\n",
    "print(\"shape of test data :\",test_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Separate the independent and dependent variables\n",
    "X = train_df.drop('label',axis=1)\n",
    "y = train_df['label']\n",
    "#perform a test-train split\n",
    "Xtrain,Xtest,ytrain,ytest = train_test_split(X,y,train_size=0.7,random_state=0)\n",
    "print(\"Train shape:\", Xtrain.shape)\n",
    "print(\"Evaluation shape:\",Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 4 different classifiers to choose the best final model\n",
    "\n",
    "#1. Basic DecisionTreeClassifier\n",
    "#2. DecisionTreeClassifier with Hyperparameter tuning\n",
    "#3. Basic RandomForestClassifier\n",
    "#4. RandomForestClassifier with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's perform a MinMaxScaling\n",
    "sclr = MinMaxScaler()\n",
    "Xtrain = sclr.fit_transform(Xtrain)\n",
    "Xtest = sclr.fit_transform(Xtest)\n",
    "\n",
    "#apply scalar to the test dataset as well\n",
    "test_df = sclr.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generic method to check the accuracy score and confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "def evaluate_model(dt_classifier):\n",
    "    print(\"Train Accuracy :\", accuracy_score(ytrain, dt_classifier.predict(Xtrain)))\n",
    "    print(\"Train Confusion Matrix:\")\n",
    "    print(confusion_matrix(ytrain, dt_classifier.predict(Xtrain)))\n",
    "    print(\"-\"*50)\n",
    "    print(\"Test Accuracy :\", accuracy_score(ytest, dt_classifier.predict(Xtest)))\n",
    "    print(\"Test Confusion Matrix:\")\n",
    "    print(confusion_matrix(ytest, dt_classifier.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 1. DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=0,max_depth=5)\n",
    "dt.fit(Xtrain,ytrain)\n",
    "evaluate_model(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 2. DecisionTreeClassifier with hyperparameter tuning\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'max_depth':[2,3,5,10,20],\n",
    "    'min_samples_leaf': [5,10,20,50,100],\n",
    "    'criterion': ['gini','entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=dt,\n",
    "                            param_grid=params,\n",
    "                            cv=4,n_jobs=-1,verbose=1,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_search.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestdt = grid_search.best_estimator_\n",
    "evaluate_model(bestdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####3. RandomForestClassifer\n",
    "rf = RandomForestClassifier(random_state=0, n_estimators=100,n_jobs=-1)\n",
    "rf.fit(Xtrain,ytrain)\n",
    "evaluate_model(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 4. RandomForestClassifier with Hyperparameter tuning\n",
    "\n",
    "#Same parameters used in @@2 can also be used here for hyperparameter tuning.\n",
    "grid_search = GridSearchCV(estimator=rf,\n",
    "                            param_grid=params,\n",
    "                            cv=4,n_jobs=-1,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_search.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestrf = grid_search.best_estimator_\n",
    "bestrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(bestrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check some classification reports\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Classification report for a simple RandomForestClassifier:\")\n",
    "print(\"\")\n",
    "print(classification_report(ytest,rf.predict(Xtest)))\n",
    "\n",
    "print(\"Classification report for a simple DecisionTreeClassifier:\")\n",
    "print(\"\")\n",
    "print(classification_report(ytest,dt.predict(Xtest)))\n",
    "\n",
    "print(\"Classification report for the RandomForestClassifier with hyperparameters tuning:\")\n",
    "print(\"\")\n",
    "print(classification_report(ytest,bestrf.predict(Xtest)))\n",
    "\n",
    "print(\"Classification report for the DecisionTreeClassifier with hyperparameters tuning:\")\n",
    "print(\"\")\n",
    "print(classification_report(ytest,bestdt.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sometimes, the simplest of the models gives us the best results.\n",
    "#The initial RandomForestClassifier that we used gave us an accuracy of 0.9616 with a precision and recall of 0.96 as well.\n",
    "\n",
    "#Thus, we will consider the simple RandomForestClassifier as our final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_pred = rf.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a report based on our final model\n",
    "df_result = pd.DataFrame(ytest_pred, columns=['Label'], index=np.arange(1,28001))\n",
    "df_result.to_csv('submission.csv',index_label='ImageId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
